# -*- coding: utf-8 -*-
"""ANN-Assignment5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ybd8msjQepvo8DcJ-sXKond2OZB1FNKz
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import scipy.io
from sklearn.model_selection import train_test_split
from scipy.io import loadmat
import matplotlib.pyplot as plt
import random
import math
import torch
import tensorflow as tf
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
from torch import optim 
from sklearn.metrics import accuracy_score ,  confusion_matrix , ConfusionMatrixDisplay

data= loadmat('/content/Matlab_cancer.mat')
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

data_x = data['x']
data_y = data['t']
data_x = np.transpose(data_x)
np.transpose(data_y)
data_y  = data_y[0]
# print(data_x.shape)
# print(data_y.shape)

train_x , test_x ,train_y , test_y= train_test_split(data_x,data_y,train_size = 0.8,shuffle=True,random_state=0)
train_x , val_x ,train_y , val_y= train_test_split(train_x,train_y,train_size = 0.8,shuffle=True,random_state=0)
# train_x = tf.convert_to_tensor(train_x)
print(train_x.shape,test_x.shape,val_x.shape)
print(train_y.shape,test_y.shape,val_y.shape)

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        # self.flatten = nn.Flatten(start_dim=1, end_dim=99)
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(100, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 1),
        )

    def forward(self, x):
        # x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        logits = torch.sigmoid(logits)
        return logits

train_x = torch.from_numpy(train_x.astype(np.float32))
test_x = torch.from_numpy(test_x.astype(np.float32))
train_y = torch.from_numpy(train_y.astype(np.float32))
test_y = torch.from_numpy(test_y.astype(np.float32))

train_y = train_y.view(train_y.shape[0], 1)
test_y = test_y.view(test_y.shape[0], 1)

print(train_x.shape,test_x.shape,val_x.shape)
print(train_y.shape,test_y.shape,val_y.shape)

train_dataloader = DataLoader(train_x, batch_size=4, shuffle=True)
test_dataloader = DataLoader(test_x, batch_size=4, shuffle=True)

model = NeuralNetwork()
num_epochs = 20
criterion = nn.BCELoss()
learning_rate = 0.001
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)

train_accuracy= []
for epoch in range(num_epochs):
    # Forward pass and loss
    y_pred = model(train_x)
    loss = criterion(y_pred, train_y)
    y_predicted_cls = y_pred.round()
    acc = y_predicted_cls.eq(train_y).sum() / float(train_y.shape[0])
    
    train_accuracy.append(acc)
    # Backward pass and update
    loss.backward()
    optimizer.step()

    # zero grad before new step
    optimizer.zero_grad()

    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}, accuracy = {acc}')

with torch.no_grad():
    y_predicted = model(test_x)
    y_predicted_cls = y_predicted.round()
    acc = y_predicted_cls.eq(test_y).sum() / float(test_y.shape[0])
    print(f'accuracy: {acc.item():.4f}')

cm = confusion_matrix(test_y, y_predicted.round())
disp_rbf = ConfusionMatrixDisplay(cm)
disp_rbf.plot()
plt.show()

plt.plot(train_accuracy)

