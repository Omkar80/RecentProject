# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14WCJ8f2Nhdg4nI8_Mi09PVdnc_ylmm0M
"""

!pip install mat4py
import pandas as pd
import os
from mat4py import loadmat
import numpy as np
import matplotlib.pyplot as plt
import sys
from sklearn.metrics import mean_squared_error, mean_absolute_error

def BT19ECE036_dataset_div_shuffle(filepath, train_test_ratio=0.2):
  ext = os.path.splitext(filepath)[1]
  # import the data
  if ext==".csv":
    data = pd.read_csv(filepath)
  elif ext==".xlsx":
    data = pd.read_excel(filepath)
  elif ext==".mat":
    load_data = loadmat(filepath) 
    datamat = load_data["accidents"]
    data = pd.DataFrame(datamat["hwydata"],columns=datamat["hwyheaders"])
    states = [x[0] for x in datamat["statelabel"]]
    data.insert(loc = 1, column = "State", value=states)
  else:
    print("File not found")
    return None
  train_frac = 1 - train_test_ratio
  test_frac = train_test_ratio
  train = data.sample(frac = train_frac)
  test = data.sample(frac = test_frac)
  return train, test

train, test = BT19ECE120_dataset_div_shuffle("/content/drive/MyDrive/Drive/Study/VNIT/Year4/Sem7/Machine Learning/Lab/Exp2/Matlab_accidents.mat")
train.head()

trainX = train[['Licensed drivers (thousands)','Registered vehicles (thousands)','Vehicle-miles traveled (millions)']]
trainy = np.array(train['Traffic fatalities'])
testX = test[['Licensed drivers (thousands)','Registered vehicles (thousands)','Vehicle-miles traveled (millions)']]
testy = np.array(test['Traffic fatalities'])

for column in trainX:
  trainX[column] = trainX[column]/np.amax(trainX[column])
for column in testX:
  testX[column] = testX[column]/np.amax(testX[column])
trainX = np.array(trainX)
testX = np.array(testX)

def linreg_pseudoinv(trainX, trainy, testX, testy):
  train_ones = np.ones([trainX.shape[0],1])
  theta_train = np.hstack((train_ones,trainX))
  weight_opt = np.matmul(np.linalg.pinv(theta_train),trainy)
  test_ones = np.ones([testX.shape[0],1])
  theta_test = np.hstack((test_ones,testX))
  y_pred = np.matmul(theta_test,weight_opt)
  plt.plot(testy)
  plt.plot(y_pred)
  print("Mean Squared Error: ",mean_squared_error(testy, y_pred))
  print("Root Mean Squared Error: ",mean_squared_error(testy, y_pred, squared = False))
  print("Mean Absolute Error: ",mean_absolute_error(testy, y_pred))

linreg_pseudoinv(trainX, trainy, testX, testy)

def gradient_descent(trainX, trainy, testX, testy, iterations=1000, learning_rate=0.01):
  X = np.concatenate((trainX, testX), axis=0)
  y = np.concatenate((trainy, testy))
  theta = np.random.randn(len(X[0]), 1)

  y_new = np.reshape(y, (len(y), 1))   
  cost_lst = []
  #vectorX = np.c_[np.ones((len(X), 1)), X]
  m = len(X)
  for i in range(iterations):
      gradients = 2/m * X.T.dot(X.dot(theta) - y_new)
      theta = theta - learning_rate * gradients
      y_pred = X.dot(theta)
      cost_value = 1/(2*len(y))*((y_pred - y)**2) 
      #Calculate the loss for each training instance
      total = 0
      for i in range(len(y)):
          total += cost_value[i][0] 
          #Calculate the cost function for each iteration
      cost_lst.append(total)
  plt.plot(np.arange(1,iterations),cost_lst[1:], color = 'red')
  plt.title('Cost function Graph')
  plt.xlabel('Number of iterations')
  plt.ylabel('Cost')
  return theta

gradient_descent(trainX, trainy, testX, testy)

